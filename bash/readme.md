## ElasticSearch | Fluent | Kibana (EFK)

<img src="https://assets.zabbix.com/img/brands/elastic.svg"  width="50" />
<img src="https://coralogix.com/wp-content/uploads/2020/04/fluentd-guide.png"  width="50" />
<img src="https://raw.githubusercontent.com/blacktop/docker-kibana-alpine/master/kibana-logo.png"  width="50" />
<img src="https://developers.redhat.com/sites/default/files/styles/article_feature/public/blog/2014/05/homepage-docker-logo.png?itok=zx0e-vcP"  width="50" />


Elastic Search | Fluentd | Kibana. 

Далее будет именоваться как (EFK) - удобный инструментарий для введения логов (журналов), их анализа и быстрого реагирования на ошибки и предупреждения в Ваших приложениях.

---

## Системные требования:

### Для запуска скрипта сборки EFK необоходимо:

- Доступ к интернету 
- Физическая / виртуальная тачка на которой можно запускать ```bash``` скрипты и установленный на ней Docker. При тестировании компонентов EFK использовалась версия docker 20.10.7 и операционая система Linux (Centos 7)

### Для запуска компонетов EFK на сервере необходимо:

- Операционная система Linux (предпочтительно Centos 7) и установленный на ней Docker .
- (Внимание!) Для production будет комфортно иметь 8 vCPU, 8gb озу и 700gb свободного места на диске. Всего этого хватит чтобы без тормозов работали 3 кластера elastic, и остальные компоненты EFK. См. примечание *(1) в самом низу страницы
- Для dev тестов хватит 3gb ОЗУ и 6gb свободного места на диске . 

---
## Сборка, загрузка на сервер и запуск компонетов EFK

В данном резделе описывается:
 - Сборка образов EFK и их загрузка на сервер
 - Параметры сборки
 - Инструкция по запуску и остановке EFK компонентов в docker контейнерах 

<br>

### Сборка и загрузка на сервер компонентов EFK

Скрипт ```build_deploy.sh``` служит для сборки и загрузки, перед тем как его запустить необходим ознакомится с его параметрами описанными в таблице #1, затем нужно будет отредактировать сам скрипт в соответствии с Вашими настройками (пользователь@серевер, количесвто кластеров и т.д). 

ВАЖНО ! Если у Вас отсутствует опыт в docker и написании bash скриптов, то рекомендуется изменять только те параметры, которые описаны в таблице #1.

После того как Вы произвели настройку, можно запустить скрипт:

```
sh build_deploy.sh 
```
### Параметры сборки . Таблица 1

| Параметр              | Значение             | Описание 
| ---                   | ----                 |      ---  
| REMOTE_SERVER         | ->                   | В параметр нужно задать значение в следующем формате имя_пользователя@ip_address
| ES_CLUSTERS_ENABLED   | false или true       | Если выставить значение true, то будут созданы скрипты для запуска нескольких кластеров <u>elastic search</u>.  При значении false, будет создаваться скрипт для запуска одного контейнера ELASTIC SEARCH. Количество создаваемых кластеров регулируется параметром   <u>ES_CLUSTERS_COUNT</u>        
| ES_CLUSTERS_COUNT     | 2 - n                | Количество создаваемых скриптов для запуска нескольких кластеров elastic search, любое положительное целочисленное число  начинающегося с 2 и выше. Данный параметр игнорируется, если он содержит значение меньше 2 или параметр ES_CLUSTERS_ENABLED выставлен в значение false. 
| EFK_FOLDER            | efk                  | Название директории, куда будут помещены все скрипты для запуска, остановки и файлы конфигурации. Так же это название используется для установки имени docker образов. Директория с этим названием будет создавать в домашней директории пользователя.
| NETWORK_NAME          | efk_net              | Название докер сети, в которой будет происходить взаимодействие компонетов efk 
| FLUENT_V              | fluent               | Название докер тома на который будут сохранятся логи fluentd


### Запуск компонентов EFK .

После успешной сборки в домашней директории должна была создаться директория ~/builds/efk в которой находятся необоходимые скрипты для запуска и оставновки компонентов EFK

Перед запуском EFK нужно загрузить docker образы, подготовить docker тома и сеть, для этого надо запустить скрипт ```init.sh``` в директории ~/builds/efk/scripts

### Для начала сделаем импорт образов:
```
cd ~/builds/efk

./import-elastic.sh
./import-fluent.sh
./import-kibana.sh
```
Подготовим docker тома и сеть:
```
cd ~/builds/efk/scripts 

./init.sh
```
### Далее запустим поочередно контейнеры в следующем порядке:
1) Elastic
2) Kibana
3) Fluentd

Внимание! Ниже будет инструкция по запуску нескольких кластеров Elastic, если вы запускаете один инстанс, то можете пропустить ее. 

Если вы  собрали сборку для нескольких кластеров Elastic Search (например 3 кластера), нужно будет отредактировать каждый скрипт запуска elastic кластера, а если быть точнее переменную окружения discovery.seed_hosts (например если Вы запускаете первый кластер ```1run.sh```, то в переменную нужно указать хосты, остальных кластеров отличных от запускаемого )  

```
cd ~/builds/efk/scripts/elastic

*(2) См примечания.
nano 1run.sh

# Отредактируйте ниже стоящую настройку кластера, затем удалите этот коментарий
-e "discovery.seed_hosts=es02,es03" \ -> Здесь оставляем как есть
# Отредактируйте выше стоящую настройку кластера, затем удалите этот коментарий

// Например если Вы запускаете второй кластер, указываете адрес первого(es01) и третьего(es03)
nano 2run.sh

# Отредактируйте ниже стоящую настройку кластера, затем удалите этот коментарий
-e "discovery.seed_hosts=es02,es03" \ -> Здесь убираем es02, и указываем другие кластеры es01, es03 
# Отредактируйте выше стоящую настройку кластера, затем удалите этот коментарий

и т.д. (Принцип везде одинаковый)

Обязательно не забудьте удалить комментарии в редактируемых bash скриптах, иначе инструкция docker run не сработает =)
```
### Запуск Elastic search:

```
# Если один инстанс
./run.sh

# Если несколько кластеров
./1run.sh
./2run.sh
....
./[n]run.sh, где n - номер запускаемого кластера 
```
### Запуск Kibana
```
cd ~/builds/efk/scripts/kibana

./run.sh
```

### Запуск Fluentd

Перед тем как запустить контейнер Fluentd, нужно примонтировать его конфигурацию с сервером где запускается контейнер и самим контейнером. Это делается для того чтобы не пересобирать образ fluentd при каждом изменении конфигурации. При таком подходе достаточно будет просто перезапустить контейнер, чтобы новые настройки вступили в силу. Конфигурационный файл находится в директории ~/builds/efk/configs  

```
cat ~/builds/efk/configs/fluent.conf

<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

...
```

Для начала необходимо выбрать место где будет хранится конфигурационный файл:

```
# Создадим директорию в корневой директории сервера (Вы можете создать директорию, где захотите - все зависит от Вас и от ваших прав доступа на сервере)

sudo mkdir -p /msdata/efk/configs # В директории fluent будет хранится конфигурация fluentd

# Затем нужно перенести конфигурационный файл, воспользуем встроенной утилитой для копирования "cp" (По дефолту она установлена на всех Linux машинах) 

sudo cp ~/builds/efk/configs/fluent.conf /msdata/configs/fluent

# Название создаваемых директорий указанных в этом примере не ограничивают Вас в именовании, Вы без проблем можете называть как захотите, НО Вам необходимо будет отредактировать run скрипт Fluentd
```
```
# Если Вы следовали этому примеру, то контейнер можно запустить сразу (без редактирования run скрипта)
```

```
# Если Вы поместили конфигурационный файл по другому пути, Вам нужно будет отредактировать run скрипт, указав путь к директории конфигурационного файла 

cd ~/builds/efk/scripts/fluentd

nano run.sh

docker run -d --name fluentd --net efk_net \
-p 24224:24224 \
-v fluent:/fluentd/log \
-v /msdata/efk/configs/:/fluentd/etc \ # вместо /msdata/efk/configs указываете полный путь до директории в которой лежит конфигурационный файл, правую же часть после двоеточия (:) оставляете не изменной
efk/fluent:1.9.1
```

```
# Теперь можно запускать контейнер fluentd

cd ~/builds/efk/scripts/fluentd

./run.sh
```

### Остановка и удаление контейнеров

```
# Это очень просто ! Нужно будет запустить stop скрипт нужного Вам контейнера

# Например остановить Kibana

cd ~/builds/efk/scripts/kibana

./stop.sh
```

---

### References
- <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs.html">Elastic Search API</a>
- <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/settings.html">настройки Elastic search</a>
- <a href="https://www.elastic.co/guide/en/kibana/current/index.html">Kibana</a>
- <a href="https://docs.fluentd.org/">Fluentd</a>
- <a href="https://www.fluentd.org/plugins">Fluentd plugins</a>, <a href="https://docs.fluentd.org/output/elasticsearch">fluentd-plugin-elastic-search</a>
- <a href="https://docs.fluentd.org/configuration/config-file">Fluentd configuration</a>

### Примечания

1) Всего этого хватит на ежедневное создание логов в размер 1gb на каждое приложение(предпологается что их у Вас будет не больше 50). Эти цифры были взяты на основе подсчета на калькуляторе и нагрузочном тестировании EFK компонентов(результаты которых не удалось зафиксировать), в данном случае лучше будет самим замерить исходя Ваших возможностей и требований или проконсультироваться с DevOps инженером. Так же с требованиями можно ознакомится в документации <a href="https://www.elastic.co/guide/en/cloud-enterprise/current/ece-hardware-prereq.html">elastic, kibana</a>, <a href="https://www.fluentd.org/architecture#:~:text=Minimum%20Resources%20Required&text=The%20vanilla%20instance%20runs%20on,the%20lightweight%20forwarder%20for%20Fluentd.">fluent</a> .
